{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ca28458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import itertools\n",
    "from torch.utils.data import random_split\n",
    "import wandb\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403d8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0d7c1985",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.getenv('WANDB_API_KEY'), 'You must set the WANDB_API_KEY environment variable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44c8ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamaboh\u001b[0m (\u001b[33mavri\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Login wandb client\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03ca78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb113fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/train/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 170498071/170498071 [13:30<00:00, 210264.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/train/cifar-10-python.tar.gz to ../data/train/\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "train_data = CIFAR10(root=\"../data/train/\",\n",
    "                     train=True,\n",
    "                     download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c21a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ../data/train/\n",
      "    Split: Train\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a10bee5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e00f69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c344de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(train_data.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fddc7219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print(train_data.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bedb6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4, 'dog': 5, 'frog': 6, 'horse': 7, 'ship': 8, 'truck': 9}\n"
     ]
    }
   ],
   "source": [
    "print(train_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6335c26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5fa57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eb6b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bfc0b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81d67206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(type(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2743869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n"
     ]
    }
   ],
   "source": [
    "print(train_data.classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "849e8214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/test/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 170498071/170498071 [04:45<00:00, 596415.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/test/cifar-10-python.tar.gz to ../data/test/\n"
     ]
    }
   ],
   "source": [
    "test_data = CIFAR10(root=\"../data/test/\",\n",
    "                    train=False,\n",
    "                    download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e33dab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../data/test/\n",
      "    Split: Test\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9174c13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=(0.4914, 0.4822, 0.4465),\n",
    "    std=(-.2023, 0.1994, 0.2010))\n",
    "])\n",
    "    \n",
    "train_data = CIFAR10(\n",
    "                    root=\"../data/test/\",\n",
    "                    train=True,\n",
    "                    download=True,\n",
    "                    transform=train_transforms\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6dabaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ../data/test/\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomCrop(size=(32, 32), padding=4)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(-0.2023, 0.1994, 0.201))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9e99e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomCrop(size=(32, 32), padding=4)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(-0.2023, 0.1994, 0.201))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(train_data.transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cb9d679",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2348512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0be67454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x16a39f4c0>\n"
     ]
    }
   ],
   "source": [
    "print(data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "667d3d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 2.4291e+00,  2.4291e+00,  2.4291e+00,  ...,  2.4291e+00,\n",
      "           2.4291e+00,  2.4291e+00],\n",
      "         [-5.1744e-01, -6.3375e-01, -6.3375e-01,  ...,  1.5955e+00,\n",
      "           1.2854e+00,  2.4291e+00],\n",
      "         [ 1.2226e-01,  4.4721e-02, -1.4913e-01,  ...,  2.4291e+00,\n",
      "           2.1189e+00,  2.4291e+00],\n",
      "         ...,\n",
      "         [ 1.3435e+00, -9.2452e-01, -1.1765e+00,  ..., -1.4673e+00,\n",
      "          -1.8356e+00,  2.4291e+00],\n",
      "         [ 1.3435e+00, -6.7252e-01, -2.2667e-01,  ..., -1.4673e+00,\n",
      "          -1.6030e+00,  2.4291e+00],\n",
      "         [ 5.4873e-01, -1.1378e+00, -1.1036e-01,  ..., -9.2452e-01,\n",
      "          -1.0602e+00,  2.4291e+00]],\n",
      "\n",
      "        [[-2.4183e+00, -2.4183e+00, -2.4183e+00,  ..., -2.4183e+00,\n",
      "          -2.4183e+00, -2.4183e+00],\n",
      "         [ 4.0101e-02,  1.7777e-01,  1.3844e-01,  ..., -1.5136e+00,\n",
      "          -1.1989e+00, -2.4183e+00],\n",
      "         [-7.8591e-01, -6.8757e-01, -5.3024e-01,  ..., -2.4183e+00,\n",
      "          -2.0249e+00, -2.4183e+00],\n",
      "         ...,\n",
      "         [-1.8479e+00,  4.1377e-01,  6.3011e-01,  ...,  5.3177e-01,\n",
      "           1.1611e+00, -2.4183e+00],\n",
      "         [-1.8086e+00,  1.9744e-01, -3.5324e-01,  ...,  5.9077e-01,\n",
      "           9.2511e-01, -2.4183e+00],\n",
      "         [-1.1989e+00,  4.9244e-01, -5.6957e-01,  ...,  7.6703e-04,\n",
      "           3.1544e-01, -2.4183e+00]],\n",
      "\n",
      "        [[-2.2214e+00, -2.2214e+00, -2.2214e+00,  ..., -2.2214e+00,\n",
      "          -2.2214e+00, -2.2214e+00],\n",
      "         [-2.3134e-01, -1.1428e-01, -1.9232e-01,  ..., -1.3434e+00,\n",
      "          -9.9224e-01, -2.2214e+00],\n",
      "         [-1.2459e+00, -1.1483e+00, -1.0508e+00,  ..., -2.2214e+00,\n",
      "          -1.8312e+00, -2.2214e+00],\n",
      "         ...,\n",
      "         [-2.0458e+00, -5.2400e-01, -3.0938e-01,  ..., -1.7922e+00,\n",
      "          -4.4596e-01, -2.2214e+00],\n",
      "         [-2.0848e+00, -8.5567e-01, -1.0508e+00,  ..., -1.5580e+00,\n",
      "          -3.4841e-01, -2.2214e+00],\n",
      "         [-1.5580e+00, -3.8743e-01, -1.1093e+00,  ..., -1.4020e+00,\n",
      "          -3.4841e-01, -2.2214e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca765d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ../data/test\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.201))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    (0.4914, 0.4822, 0.4465),\n",
    "    (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root= \"../data/test\",\n",
    "    train=False,\n",
    "    transform=test_transforms\n",
    ")\n",
    "\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fda3ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = random_split(\n",
    "                      train_data,\n",
    "                      [40000, 10000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "                train_set,\n",
    "                batch_size=16,\n",
    "                shuffle=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4b8496b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "data_batch, labels_batch = next(iter(trainloader))\n",
    "print(data_batch.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b095c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "print(labels_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "664da741",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(\n",
    "              test_data,\n",
    "              batch_size = 16,\n",
    "              shuffle=False\n",
    "            )\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "                    val_set,\n",
    "                    batch_size=16,\n",
    "                    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a215c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "try: \n",
    "    vgg16 = models.vgg16(weights='DEFAULT')\n",
    "except Exception as e:\n",
    "    print(f'Exception: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "122ab368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace=True)\n",
      "  (5): Dropout(p=0.5, inplace=False)\n",
      "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg16.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47349694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/ama/.cache/torch/hub/nvidia_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nvidia_convnets_processing_utils',\n",
       " 'nvidia_efficientnet',\n",
       " 'nvidia_efficientnet_b0',\n",
       " 'nvidia_efficientnet_b4',\n",
       " 'nvidia_efficientnet_widese_b0',\n",
       " 'nvidia_efficientnet_widese_b4',\n",
       " 'nvidia_fastpitch',\n",
       " 'nvidia_gpunet',\n",
       " 'nvidia_hifigan',\n",
       " 'nvidia_resneXt',\n",
       " 'nvidia_resnet50',\n",
       " 'nvidia_resnext101_32x4d',\n",
       " 'nvidia_se_resnext101_32x4d',\n",
       " 'nvidia_ssd',\n",
       " 'nvidia_ssd_processing_utils',\n",
       " 'nvidia_tacotron2',\n",
       " 'nvidia_textprocessing_utils',\n",
       " 'nvidia_tft',\n",
       " 'nvidia_tft_data_utils',\n",
       " 'nvidia_tts_utils',\n",
       " 'nvidia_waveglow']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hub.list(\n",
    "      'nvidia/DeepLearningExamples:torchhub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b16ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SmallNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(SmallNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2048, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 2048)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "722e669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.SmallNet'>\n"
     ]
    }
   ],
   "source": [
    "smallnet = SmallNet()\n",
    "print(SmallNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8f258a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand(2048)\n",
    "output = smallnet(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7aeef828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),\n",
    "                        (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1,\n",
    "                   int(x.nelement() / x.shape[0]))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3365c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "543fb5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6eafcd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "lr=0.001\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1811e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "model = LeNet5().to(device=device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                     lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4a3bf62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "458480b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:a8nl3m3x) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██</td></tr><tr><td>test accuracy</td><td>▁</td></tr><tr><td>train loss</td><td>█▅▄▃▃▂▂▁▁▁</td></tr><tr><td>val loss</td><td>█▆▅▄▃▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9</td></tr><tr><td>test accuracy</td><td>0.2526</td></tr><tr><td>train loss</td><td>1.20114</td></tr><tr><td>val loss</td><td>1.24148</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-firefly-5</strong> at: <a href='https://wandb.ai/avri/Effective_MLOPs_CICD_CV/runs/a8nl3m3x' target=\"_blank\">https://wandb.ai/avri/Effective_MLOPs_CICD_CV/runs/a8nl3m3x</a><br/> View job at <a href='https://wandb.ai/avri/Effective_MLOPs_CICD_CV/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNTc3NTM2OQ==/version_details/v3' target=\"_blank\">https://wandb.ai/avri/Effective_MLOPs_CICD_CV/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEyNTc3NTM2OQ==/version_details/v3</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231228_103651-a8nl3m3x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:a8nl3m3x). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Volumes/AM/Desktop/MLOPs/Effective-MLOPS/notebooks/wandb/run-20231228_111959-ewih6btk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/avri/Effective_MLOPs_CICD_CV/runs/ewih6btk' target=\"_blank\">dulcet-dawn-6</a></strong> to <a href='https://wandb.ai/avri/Effective_MLOPs_CICD_CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/avri/Effective_MLOPs_CICD_CV' target=\"_blank\">https://wandb.ai/avri/Effective_MLOPs_CICD_CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/avri/Effective_MLOPs_CICD_CV/runs/ewih6btk' target=\"_blank\">https://wandb.ai/avri/Effective_MLOPs_CICD_CV/runs/ewih6btk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"Effective_MLOPs_CICD_CV\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    tags=['challengerV1'],\n",
    "    config={\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": N_EPOCHS,\n",
    "        \"optimizer\":\"Adam\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f3a6f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: 1.6986474369049072 Val Loss: 1.5111891620635987\n",
      "Epoch: 1 Train Loss: 1.4647838483572007 Val Loss: 1.4184259377479553\n",
      "Epoch: 2 Train Loss: 1.3743178421974183 Val Loss: 1.4236837748527527\n",
      "Epoch: 3 Train Loss: 1.322928121304512 Val Loss: 1.3030801772117615\n",
      "Epoch: 4 Train Loss: 1.2774642323493957 Val Loss: 1.3171323024749755\n",
      "Epoch: 5 Train Loss: 1.2456189161539077 Val Loss: 1.2583462390899658\n",
      "Epoch: 6 Train Loss: 1.2220693056941032 Val Loss: 1.2672287676811218\n",
      "Epoch: 7 Train Loss: 1.1915092902779578 Val Loss: 1.2265211025238036\n",
      "Epoch: 8 Train Loss: 1.171791988992691 Val Loss: 1.201218919658661\n",
      "Epoch: 9 Train Loss: 1.1568260403513908 Val Loss: 1.1752229278564452\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    # Training\n",
    "    train_loss = 0.0\n",
    "    model.train()  # Set the model to training mode\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Log training loss\n",
    "    avg_train_loss = train_loss / len(trainloader)\n",
    "    wandb.log({\"epoch\": epoch, \"train loss\": avg_train_loss})\n",
    "\n",
    "    # Validation\n",
    "    val_loss = 0.0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No gradient computation\n",
    "        for inputs, labels in valloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Log validation loss\n",
    "    avg_val_loss = val_loss / len(valloader)\n",
    "    wandb.log({\"epoch\": epoch, \"val loss\": avg_val_loss})\n",
    "\n",
    "    print(\n",
    "      \"Epoch: {} Train Loss: {} Val Loss: {}\".format(\n",
    "                  epoch, avg_train_loss, avg_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a56f5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625 16\n",
      "Test Accuracy: 0.2517000138759613\n"
     ]
    }
   ],
   "source": [
    "num_correct = 0.0\n",
    "for x_test_batch, y_test_batch in testloader:\n",
    "  model.eval() \n",
    "  y_test_batch = y_test_batch.to(device)\n",
    "  x_test_batch = x_test_batch.to(device)\n",
    "  y_pred_batch = model(x_test_batch) \n",
    "  _, predicted = torch.max(y_pred_batch, 1) \n",
    "  num_correct += (predicted ==\n",
    "    y_test_batch).float().sum() \n",
    "\n",
    "accuracy = num_correct/(len(testloader) \\\n",
    "  *testloader.batch_size) \n",
    "\n",
    "print(len(testloader), testloader.batch_size)\n",
    "\n",
    "print(\"Test Accuracy: {}\".format(accuracy))\n",
    "wandb.log({\"test accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "91479eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb.apis.reports as wr\n",
    "\n",
    "PROJECT = 'Effective_MLOPs_CICD_CV'\n",
    "ENTITY = 'avri'\n",
    "\n",
    "report = wr.Report(\n",
    "    entity=ENTITY,\n",
    "    project=PROJECT,\n",
    "    title = \"Compare Runs\",\n",
    "    description=\"comparing runs of model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93865bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m A graphql request initiated by the public wandb API timed out (timeout=9 sec). Create a new API with an integer timeout larger than 9, e.g., `api = wandb.Api(timeout=19)` to increase the graphql timeout.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe src='https://wandb.ai/avri/Effective_MLOPs_CICD_CV/reports/Compare-Runs--Vmlldzo2MzY4MzQy?jupyter=true' style='border:none;width:100%;height:1024px;'></iframe>"
      ],
      "text/plain": [
       "Report(project='Effective_MLOPs_CICD_CV', entity='avri', title='Compare Runs', description='comparing runs of model', width='readable', blocks=[PanelGrid(runsets=[Runset(entity='avri', project='Effective_MLOPs_CICD_CV', name='Run Comparison', query='', filters={'$or': [{'$and': [{'displayName': {'$in': ['skilled-firefly-5', 'dulcet-dawn-6']}}]}]}, order=['-CreatedTimestamp'])], panels=[RunComparer(diff_only='split')])])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg = wr.PanelGrid(\n",
    "    runsets=[\n",
    "        wr.Runset(ENTITY, PROJECT, \"Run Comparison\").set_filters_with_python_expr(\"Name in ['skilled-firefly-5', 'dulcet-dawn-6']\")\n",
    "    ],\n",
    "    panels=[\n",
    "        wr.RunComparer(diff_only='split', layout={'w': 24, 'h': 15}),\n",
    "    ]\n",
    ")\n",
    "\n",
    "report.blocks = report.blocks[:1] + [pg] + report.blocks[1:]\n",
    "report.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8bfbdc41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://wandb.ai/avri/Effective_MLOPs_CICD_CV/reports/Compare-Runs--Vmlldzo2MzY4MzQy'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a12eb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('model_pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9771618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
